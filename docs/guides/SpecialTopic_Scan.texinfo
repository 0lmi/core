\input texinfo-altfont
\input texinfo-logo
\input texinfo
@selectaltfont{cmbright}
@setlogo{CFEngineFrontPage}

@c *********************************************************************
@c
@c  This is a TEXINFO file. It generates both TEX documentation and
@c  the "on line" documentation "info" files.
@c
@c  The file is structured like a programming language. Each chapter
@c  starts with a chapter comment.
@c
@c  Menus list the subsections so that an online info-reader can parse
@c  the file hierarchically.
@c
@c ***********************************************************************
@c %** start of header
@setfilename st-scan.info
@settitle Security Scanning with CFEngine
@setchapternewpage odd
@c %** end of header

@titlepage
@title Security Scanning with CFEngine
@subtitle A CFEngine Special Topics Handbook
@author CFEngine AS


@page

@cartouche
@quotation

This document describes how to scan systems for potential security
incidents and vulnerabilities.

@end quotation
@end cartouche

@vskip 0pt plus 1filll
Copyright @copyright{} October 2011 CFEngine AS

@end titlepage



@c *************************** File begins here ************************


@ifinfo
@dircategory CFEngine Training
@direntry
* CFEngine Iteration:
                      CFEngine is a language based tool specifically
                      designed for configuring and maintaining
                      Unix-like operating systems attached
                      to a TCP/IP network.
@end direntry
@end ifinfo

@ifnottex
@node Top, Architecture Principles, (dir), (dir)
@top Security scanning
@end ifnottex

@contents


@node
@unnumberedsec Intrusion detection


What is an intrusion or an attempted intrusion? This can be difficult
to define. If someone tries to login at root once? If someone tries to
login at root fifty times? Port scanning, SATAN or ISS scan? Someone
trying a known security hole? These things are quite uncertain. The
aim of an intrusion detection system is to detect events that can be
plausibly connected to break-ins, hopefully while they are still in
progress so that something can be done about them.

Intrusion detection is a special form of fault-diagnosis. Faults (in a
security system) are events that are not supposed to happen, but the
fact is that they do happen. As with all fault diagnosis systems,
Intrusion Detection Systems (IDS) give the wrong answers from time to
time. Because it is so difficult to define what intrusion actually
means in a generic sense intrusion detection systems tend to err on
the side of caution and report many false positives, i.e. false
alarms.

One way of doing fault diagnosis is to compare a system to a working
specification continuously. This is essentially what cfengine does
with systems.

There are many approaches to intrusion detection. These go well beyond
the scope of this document. Suffice it to say that cfengine is not
meant to be an intrusion detection system specifically. One thing
cfengine can detect however is change, and unexpected changes can
sometimes be interpreted as tell-tale signs of something unauthorized
happening. So there is scope for using cfengine as part of a
host-based intrusion system. CFEngine does not, however, try to
examine and diagnose network traffic.


@node
@unnumberedsec Change Detection

Change monitoring is about detecting when stored data, or other
measurable aspects of a computer system change. A change detection
system is not normally concerned with the reason for a change, but if
you are monitoring for change then we shall take it for granted
somehow that you are expecting to find changes that you didn't plan
for yourself.

@node
@subsection Laying tripwires with cryptographic hashes

The most important bulk of information on a computer is its filesystem
data. Change detection for filesystems uses a technique made famous in
the program Tripwire, which collects a snapshot" of the system in the
form of a database of file checksums (cryptographic hashes) and
permissions and rechecked the system against this database at regular
intervals. Tripwire examines files, and looks for change in their
contents or their attributes. This is a very simple (even simplistic)
view of change. If a legitimate change is made to the system, such a
system responds to this as a potential threat. Databases must then be
altered, or rebuilt.


A cryptographic hash (also called a digest) is an algorithm that reads
(digests) a file and computes a single number (the hash value) that is
based on the contents. If so much as a single bit in the file changes
then the value of the hash will change. You can compute hash values
manually, for example:

 
@verbatim

host$ openssl md5 /etc/passwd
MD5(/etc/passwd)= 1fbd82252c441d0e9539f8f7271ec2fe

@end verbatim

There are several kinds of hash function. The most common ones are MD5
and SHA1. Recently both of the algorithms that create these hashes
have been superceded by the newer SHA2.

@cartouche
Note that the FIPS 140-2 standard for encryption does not recognize
the MD5 hash algorithm. The default algorithm for enterprise grade
CFEngine is now SHA256.
@end cartouche


@node
@subsection Computing hashes

CFEngine has adopted part of the Tripwire model, but with a few
provisoes. Tripwire assumes that all change is unauthorized and is
bad. CFEngine cannot reasonably take this viewpoint. CFEngine expects
systems to change dynamically, so it allows users to define a policy
for what changes are considered to be okay.

Integrity checks on files whose contents are supposed to be static are
a good way to detect tampering with the system, from whatever
source. Running MD5 or SHA1 checksums of files regularly provides us
with a way of determining even the smallest changes to file contents.

To use the checksum based change detection we first ask cfengine to
collect MD5 hash data for specified files. Here is an excerpt from a
cfengine configuration program that would check the /usr/local
filesystem for file changes. Note that it excludes files such as log
files that we therefore allow to change (log files are supposed to
change):

@verbatim
files:

  "/home/mark/tmp/web" -> "me"

   changes      => detect_all_change,
   depth_search => recurse("inf");

@end verbatim

The first time we run this, cfengine collects data and treats all
files as unchanged. It builds a database of the checksums. The next
time the rule is checked, cfagent recomputes the checksums and
compares the new values to the `reference' values stored in the
database. If no change has occurred, the two should match. If they
differ, then the file as changed and a warning is issued.

@verbatim
     cf3:nexus: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
     cf3:nexus: SECURITY ALERT: Checksum (md5) for /etc/passwd changed!
     cf3:nexus: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
@end verbatim

This message is designed to be visible. If you do not want the
embracing rows of `!' characters, then this control directive turns
them off:

@verbatim
body agent control
{
exclamation => "false";
}

@end verbatim

The next question to ask is: what happens if the change that was
detected is actually okay (which is almost always the case). If you
activate this option:

@verbatim


body changes lay_a_tripwire
{
hash           => "md5";
report_changes => "content";
update         => "yes";
}

@end verbatim

Then, as soon as a change has been detected, the database is updated
and the message will not be repeated. If this is set to off, which is
the default, then warning messages will be printed each time the rule
is checked.


@node
@unnumberedsec file_change.log

The file file_hash_event_history contains a separate text log of file
changes.

     Sun Sep  7 09:42:49 2008,/usr/local/sbin/cfMonitord
     Sun Sep  7 09:42:49 2008,/usr/local/sbin/cfexecd
     Sun Sep  7 09:42:49 2008,/usr/local/sbin/cfkey_1220624104_Fri_Sep__5_16_15_15_2008_.cfsaved
     Sun Sep  7 09:42:49 2008,/usr/local/lib/libgd.so.2.0.0
     Sun Sep  7 09:42:49 2008,/usr/local/lib/libpromises.la
     Sun Sep  7 09:42:49 2008,/usr/local/lib/libcfengine.a
     Sun Sep  7 09:42:49 2008,/usr/local/lib/libgd.la
     Sun Sep  7 09:42:49 2008,/usr/local/lib/libgd.a
     Sun Sep  7 09:42:49 2008,/usr/local/lib/libcfengine.la
     Sun Sep  7 09:42:49 2008,/usr/local/lib/libpromises.a


@node
@unnumberedsec Tamperproof data

Message digests are supposed to be unbreakable, tamperproof
technologies, but of course everything can be broken by a sufficiently
determined attacker. Suppose someone wanted to edit a file and alter
the cfengine checksum database to cover their tracks. If they had
broken into your system, this is potentially easy to do. How can we
detect whether this has happened or not?

A simple solution to this problem is to use another checksum-based
operation to copy the database to a completely different host. By
using a copy operation based on a checksum value, we can also remotely
detect a change in the checksum database itself.

Consider the following code: 

@verbatim
########################################################
#
# Change detect
#
########################################################

body common control

{
bundlesequence  => { "neighbourhood_watch"  };
}

########################################################

bundle agent neighbourhood_watch

{
vars:

  "neighbours" slist => peers("/var/cfengine/inputs/hostlist","#.*",4);

files:

  # Redundant cross monitoring .......................................

  "$(sys.workdir)/nw/$(neighbours)_checksum_digests.db"

     comment => "Watch our peers remote hash tables and keep a local copy",
    copyfrom => remote_cp("$(sys.workdir)/checksum_digests.db",$(neighbours)),
  depends_on => { "grant_hash_tables" };

  # Define the actual children to watch over .........................

   "/usr/bin"         

      comment     => "Watch over the system binaries - changes are mostly updates",
      changes      => detect_all_change,
      depth_search => recurse("inf"),
      action       => measure;

}
@end verbatim

It works by building a list of neighbours for each host. The function
SelectPartitionNeighbours can be used for this. Using a file which
contains a list of all hosts running cfengine (e.g. the cfrun.hosts
file), we create a list of hosts to copy databases from. Each host in
the network therefore takes on the responsibility to watch over its
neighbours.

The copy rule attempts to copy the database to some file in a
safekeeping directory. We label the destination file with $(this)
which becomes the name of the server from which the file was
collected. Finally, we backup any successful copies using a timestamp
to retain a complete record of all changes on the remote host. Each
time a change is detected, a copy will be kept of the old. The rule
contains triggers to issue alerts and warnings too just to make sure
the message will be heard.

In theory, all four neigbours should signal this change. If an
attacker had detailed knowledge of the system, he or she might be able
to subvert one or two of these before the change was detected, but it
is unlikely that all four could be covered up. At any rate, this
approach maximizes the chances of change detection.

Finally, in order to make this copy, you must, of course, grant access to the database in cfservd.conf. 

@verbatim
     # cfservd.conf

     admit:

     any::

       /var/cfengine/checksum_digests.db  mydomain.tld
@end verbatim

Let us now consider what happens if an attacker changes a file an
edits the checksum database. Each of the four hosts that has been
designated a neighbour will attempt to update their own copy of the
database. If the database has been tampered with, they will detect a
change in the md5 checksums of the remote copy versus the
original. The file will therefore be copied.

It is not a big problem that others have a copy of your checksum
database. They cannot see the contents of your files from this. A
potentially greater problem is that this configuration will unleash an
avalanche of messages if a change is detected. This does make messages
visible however.



@node 
@unnumberedsec Scanning logs with cf-monitord
@sp 1

In CFEngine Nova and above, you can extract data from the
system in sophisticated ways from files or pipes, using Perl
Compatible Regular Expressions to match text. The @code{cf-monitord}
agent is responsible for processing measurement promises.

In this example, we count lines matching a pattern in a file.
You might want to scan a log for instances of a particular
message and trace this number over time.


@node  Scanning log files for patterns, FTP, measurements promises, Monitoring customization
@unnumberedsubsec Scanning log files for patterns
@sp 1

You will have to scan the log file for each separate summary
you want to keep, so you win a lot of efficiency by lumping
together mulitple patterns in a longer regular expressions.

Be careful however about the trade-off. Disk access is certainly the
most expensive computing resource, but a smart filesystem might do good caching.

Regular expression processing, on the other hand, is CPU expensive, so
if you have very long or complex patterns to match, you will begin
to eat up CPU time too. 

At the end of the day, you should probably do some tests to find a good
balance.  One goal of CFEngine is to minimally impact your system performance,
but it is possible to write promises that have the opposite effect.  Check
your work!

@verbatim

bundle monitor watch
{
measurements:

   "/home/mark/tmp/file"

         handle => "line_counter",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log("MYLINE.*"),
   history_type => "log",
         action => sample_rate("0");

}

##########################################################

body match_value scan_log(line)
{
select_line_matching => "$(line)";
track_growing_file => "true";
}

body action sample_rate(x)
{
ifelapsed => "$(x)";
expireafter => "10";
}
@end verbatim

@node  FTP, DNS, Scanning log files for patterns, Monitoring customization
@unnumberedsubsec Scanning syslog for FTP statistics
@sp 1

There are many things that you can set CFEngine at monitoring.  For example,
CFEngine can automtically collect information about the number of socket-level
connections made to the ftp server, but you might want more detailed
statistics.  For example, you might want to track the volume of data sent
and received, or the number of failed logins.  Here are a collection of
monitoring promises for doing just that.

Note that the ftp logs are maintained by syslog, so it is necessary to match
only those lines which correspond to the appropriate service.  We also assume
that the specific messages are sent to @file{/var/log/messages}, while your
configuration may specify otherwise.  Likewise, your operating systems's
version of ftp may issue messages with a slightly different format than ours

@verbatim

bundle monitor watch_ftp
{
vars:
   "dir" slist => { "get", "put" };

measurements:

   "/var/log/messages"

	handle => "ftp_bytes_${dir}",
   stream_type => "file",
     data_type => "int",
   match_value => extract_log(".*ftpd\[.*", ".*${dir} .* = (\d+) bytes.*"),
  history_type => "log",
	action => sample_rate("0");

   "/var/log/messages"

	handle => "ftp_failed_login",
   stream_type => "file",
     data_type => "counter",
   match_value => scan_log(".*ftpd\[.*", ".*FTP LOGIN FAILED.*"),
  history_type => "log",
	action => sample_rate("0");

   "/var/log/messages"

	handle => "ftp_failed_anonymous_login",
   stream_type => "file",
     data_type => "counter",
   match_value => scan_log(".*ftpd\[.*", ".*ANONYMOUS FTP LOGIN REFUSED.*"),
  history_type => "log",
	action => sample_rate("0");

}

##########################################################

body match_value scan_log(line)
{
select_line_matching => "$(line)";
track_growing_file => "true";
}

body match_value extract_log(line, extract)
{
select_line_matching => "$(line)";
extraction_regex => "$(extract)";
track_growing_file => "true";
}

body action sample_rate(x)
{
ifelapsed => "$(x)";
expireafter => "10";
}
@end verbatim

@node  DNS, Email, FTP, Monitoring customization
@unnumberedsubsec Scanning DNS logs for query statistics
@sp 1

Another thing you might want to do is monitor the types of queries that your
DNS server is being given.  One possible reason for this is to test for
unusual behavior.  For example, suddenly seeing a surge in @samp{MX} requests
might indicate that your system is being targeted by spammers (or that one of
your users is sending spam).  If you are thinking of converting to IPv6, you
might want to compare the number of @samp{A} requests to @samp{AAAA} and
@samp{A6} requests to see how effective your IPv6 implementation is.

Because DNS logs are directly maintained by @samp{bind} or @samp{named} (and
do not go through syslog), the parsing can be simpler.  However, you @i{do}
need to configure DNS to log query requests to the appropriate log file.  In
our case, we use @file{/var/log/named/queries}.

@verbatim

bundle monitor watch_dns
{
vars:
    "query_type" slist => { "A", "AAAA", "A6", "CNAME", "MX", "NS",
                            "PTR", "SOA", "TXT", "SRV", "ANY" };
measurements:
    "/var/log/named/queries"
        handle => "DNS_$(query_type)_counter",
        stream_type => "file",
        data_type => "counter",
        match_value => scan_log(".* IN $(query_type).*"),
        history_type => "log",
        action => sample_rate("0");
}

##########################################################

body match_value scan_log(line)
{
select_line_matching => "$(line)";
track_growing_file => "true";
}

body action sample_rate(x)
{
ifelapsed => "$(x)";
expireafter => "10";
}
@end verbatim

@node  Email, Milter, DNS, Monitoring customization
@unnumberedsubsec Scanning syslog for email statistics
@sp 1

Email is another syslog-based facility that you may want to use CFEngine to
monitor.  There are a number of volumetric data that are of interest.  For
example, the number of messages sent and received, the number of messages
that have been deferred (a large number might indicate networking problems or
spam bounces), and the number of spam messages that have been
detected and removed by the assorted spam filters.

The samples below assume that there is a separate logfile for email (called
@file{/var/log/maillog}) and that a few of the standard sendmail rulesets
have been enabled (see
@samp{http://www.sendmail.org/~ca/email/relayingdenied.html} for details).
As with any syslog-generated file, you need to check for the appropriate
service, and in this case we are lumping local messages (sent through
@samp{sm-mta}) and remote messages (sent through @samp{sendmail}) into a
single count.  Your mileage may of course vary.

If you use one or more sendmail "milters", each of these will also output
their own syslog messages, and you may choose to track the volume of
rejections on a per-filter basis.

@verbatim

bundle monitor watch_email
{
vars:
    "sendmail" string => ".*(sendmail|sm-mta)\[.*";

    "action" slist => { "Sent", "Deferred" };

measurements:

   "/var/log/maillog"

         handle => "spam_rejected",
    stream_type => "file",
      data_type => "counter",
                   # This matches 3 kinds of rulesets: check_mail,
		   # check_rcpt, and check_relay
    match_value => scan_log("$(sendmail)ruleset=check_(mail|rcpt|relay).*"),
   history_type => "log",
         action => sample_rate("0");

   "/var/log/maillog"

         handle => canonify("mail_$(action)",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log("$(sendmail)stat=$(action) .*"),
   history_type => "log",
         action => sample_rate("0");

}

##########################################################

body match_value scan_log(line)
{
select_line_matching => "$(line)";
track_growing_file => "true";
}

body action sample_rate(x)
{
ifelapsed => "$(x)";
expireafter => "10";
}
@end verbatim


@node  Milter, Breakin, Email, Monitoring customization
@unnumberedsubsec Scanning syslog for email milter failures
@sp 1

Milters are relatively new in sendmail, and some have problems.  You can also
use monitoring to detect certain types of failure modes.  For example, if a
milter is running (that is, there is a process present) but it does not
respond correctly, sendmail will log an entry like this in syslog (where
@samp{xyzzy} is the name of the milter in question):

@verbatim
Milter (xyzzy): to error state
@end verbatim

A small number of these messages is no big deal, since sometimes the milter
has temporary problems or simply encounters an email message that it finds
confounding.  But a larger value of these messages usually indicates that the
milter is in a broken state, and should be restarted.

You can use @samp{cf-monitord} to check for the number of these kinds of
messages, and use the soft classes that it creates to change how
@samp{cf-agent} operates.  For example, here we will restart any milter
which is showing a high number of failure-mode messages:

@verbatim
bundle monitor watch_milter
{
vars:
   "milter" slist => { "dcc", "bogom", "greylist" };

measurements:

   "/var/log/maillog"

         handle => "${milter}_errors",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*Milter (${milter}): to error state"),
   history_type => "log",
         action => sample_rate("0");
}

bundle agent fix_milter
{
vars:
    "m[dcc]" string      => "/var/dcc/libexec/start-dccm";
    "m[bogom]" string    => "/usr/local/etc/rc.d/milter-bogom.sh restart";
    "m[greylist]" string => "/usr/local/etc/rc.d/milter-greylist restart";

commands:
    "$(m[$(watch_milter.milter)])"
	ifvarclass => "$(watch_milter.milter)_high";
}
@end verbatim


@node  Breakin, Threshold monitoring, Milter, Monitoring customization
@unnumberedsubsec Scanning syslog for breakin attempts
@sp 1

A lot of script-kiddies will probe your site for vulnerabilities, using
dictionaries of account/password combinations, looking for unguarded accounts
or accouts with default passwords.  Most of these scans are harmless, because
a well-maintained site will not use the default passwords that these hackers
seek to exploit.

However, knowing that you are being scanned is a good thing, and CFEngine can
help you find that out.  Because @samp{sshd} logs it's message through
@samp{syslog}, we again need to filter lines based on the service name.  On
our system, authorization messages are routed to @file{/var/log/auth.log},
and we would monitor it like this:

@verbatim
bundle monitor watch_breakin_attempts
{
measurements:
    "/var/log/auth.log"
	 # This is likely what you'll see when a script kiddie probes
	 # your system

         handle => "ssh_username_probe",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*Invalid user.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # As scary as this looks, it may just be because someone's DNS
	 # records are misconfigured - but you should double check!

         handle => "ssh_reverse_map_problem",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*POSSIBLE BREAK-IN ATTEMPT!.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # Someone is trying to log in to an account that is locked
	 # out in the sshd config file

         handle => "ssh_denygroups",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*group is listed in DenyGroups.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # This is more a configuration error in /etc/passwd than a
	 # breakin attempt...

         handle => "ssh_no_shell",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*because shell \S+ does not exist.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # These errors usually indicate a problem authenticating to your
	 # IMAP or POP3 server

         handle => "ssh_pam_error",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*error: PAM: authentication error.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # These errors usually indicate that you haven't rebuilt your
	 # database after changing /etc/login.conf - maybe you should
	 # include a rule to do this command: cap_mkdb /etc/login.conf

         handle => "ssh_pam_error",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*login_getclass: unknown class.*"),
   history_type => "log",
         action => sample_rate("0");
}

@end verbatim


See the CFEngine Nova documentation for more possibilities of measurement
promises.



@node Threshold monitoring, Summary Monitoring, Breakin, Monitoring customization
@unnumberedsubsec Threshold monitoring

@verbatim
vars:

 "probes" slist => { "www", "smtp", "ssh" };

classes:

 "$(probes)_threshold" expression => isgreaterthan("$(mon.$(probes))","50");

reports:

  "Help $(probes)!" ifvarclass => "$(probes)_threshold";

@end verbatim



@node
@unnumberedsec TCP dump

CFEngine cf-montord has the ability to interact with tcpdump, if it is installed on your
system. You can collect data.


@bye
