\input texinfo-altfont
\input texinfo-logo
\input texinfo
@selectaltfont{cmbright}
@setlogo{CFEngineFrontPage}

@c *********************************************************************
@c
@c  This is a TEXINFO file. It generates both TEX documentation and
@c  the "on line" documentation "info" files.
@c
@c  The file is structured like a programming language. Each chapter
@c  starts with a chapter comment.
@c
@c  Menus list the subsections so that an online info-reader can parse
@c  the file hierarchically.
@c
@c ***********************************************************************
@c %** start of header
@setfilename st-scan.info
@settitle Security Scanning with CFEngine
@setchapternewpage odd
@c %** end of header

@titlepage
@title Security Scanning with CFEngine
@subtitle A CFEngine Special Topics Handbook
@author CFEngine AS


@page

@cartouche
@quotation

CFEngine has sophisticated functionality for scanning hosts to find
anomalous content, for looking through log messages and detecting unauthorized file
changes. This can form the basis of a host based intrusion shield,
either alone or in conjunction with other tools.

This document describes how to scan systems for potential security
incidents and vulnerabilities, and view reports across your system
using the Mission Portal.

@end quotation
@end cartouche

@vskip 0pt plus 1filll
Copyright @copyright{} October 2011 CFEngine AS

@end titlepage



@c *************************** File begins here ************************


@ifinfo
@dircategory CFEngine Training
@direntry
* CFEngine Iteration:
                      CFEngine is a language based tool specifically
                      designed for configuring and maintaining
                      Unix-like operating systems attached
                      to a TCP/IP network.
@end direntry
@end ifinfo

@ifnottex
@node Top, , (dir), (dir)
@top Security scanning with CFEngine
@end ifnottex

@contents

@node File scanning
@chapter File scanning

CFEngine has sophisticated functionality for scanning hosts to find
anomalous content, for looking through log messages and detecting unauthorized file
changes. This can form the basis of a host based intrusion shield,
either alone or in conjunction with other tools.

This document describes how to scan systems for potential security
incidents and vulnerabilities, and view reports across your system
using the Mission Portal.


@node File change detection: tripwires, , Security scanning, Security scanning
@section File change detection: tripwires

File change monitoring is about detecting when file information on a
computer system changes. You might or might not know that files
are going to change. Expected changes are not usually a problem,
but unexpected change can be problematic or even sinister.

The bulk of information on a computer is its filesystem data. Change
detection for filesystems uses a technique made famous in the original
open source program Tripwire, which collects a snapshot of the system
in the form of a database of file checksums (cryptographic hashes) and
then periodically rechecks the system against this database to see
what has changed. Using cryptographic hashes is an efficient way of
detecting change as it reduces file contents to a unique number, just
a few bytes long.

If as much as a single bit of information changes, the file hash will
change by a noticable amount.  This is a very simple (even simplistic)
view of change. If a legitimate change is made to the system, such a
system responds to this as a potential threat. Databases must then be
altered, or rebuilt.

@cartouche
A cryptographic hash (also called a digest) is an algorithm that reads
(digests) a file and computes a single number (the hash value) that is
based on the contents. If so much as a single bit in the file changes
then the value of the hash will change. You can compute hash values
manually, for example:

@verbatim

host$ openssl md5 /etc/passwd
MD5(/etc/passwd)= 1fbd82252c441d0e9539f8f7271ec2fe

@end verbatim

There are several kinds of hash function. The most common ones are MD5
and SHA1. Recently both of the algorithms that create these hashes
have been superceded by the newer SHA2.

@sp 1
Note that the FIPS 140-2 US government standard for encryption does not recognize
the MD5 hash algorithm. The default algorithm for enterprise grade
CFEngine is now SHA256.
@end cartouche


@sp 1

To use the hash based change detection we first ask CFEengine to
compute file hashes for specified files and enter them into a
database. Then, the same promise on subsequent runs will re-collect
the data and compare the result to what has been stored in the database.

Here is a simple CFEngine promise that would check the
@file{/usr/local} filesystem for file changes. Note that it excludes
files such as log files that we therefore allow to change (log files
are supposed to change):

@verbatim
files:
  "/usr/local"
     changes      => detect_all_change,
     depth_search => recurse("inf");
@end verbatim

The first time this promise is kept, CFEngine collects data and treats all
files as @i{unchanged}. It builds a database of the checksums. The next
time the rule is checked, cfagent recomputes the checksums and
compares the new values to the `reference' values stored in the
database. If no change has occurred, the two should match. If they
differ, then the file as changed and a warning is issued.

@verbatim
   cf3: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   cf3: SECURITY ALERT: Checksum (sha256) for /etc/passwd changed!
   cf3: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
@end verbatim

This message is designed to be visible. If you do not want the
embracing rows of `!' characters, then this control directive turns
them off:

@verbatim
body agent control
{
exclamation => "false";
}
@end verbatim


@node Automatic updating of the database or not
@section Automatic updating of the database -- or not

The next question to ask is: what happens if the change that was
detected is actually okay (which is almost always the case). If you
activate this option:

@verbatim

body changes lay_a_tripwire
{
hash           => "md5";
report_changes => "content";
update         => "yes";
}

@end verbatim

Then, as soon as a change has been detected, the database is updated
and the message will not be repeated. If this is set to off, which is
the default, then warning messages will be printed each time the rule
is checked.


@node file_change.log, , File change detection: tripwires, Security scanning
@section file_change.log

The file file_hash_event_history contains a separate text log of file
changes.

@verbatim
host$ sudo more /var/cfengine/state/file_change.log 
[sudo] password for you: 
1308904847,/etc/passwd
1308904847,/etc/shadow
@end verbatim
The first column is a time stamp.



@node File change reports in Nova and Constellation, , file_change.log, Security scanning
@section File change reports in Nova and Constellation

In the commercially supported editions of CFEngine, users have access
to a number of reports about file changes.

@sp 1
@image{file_change_diffs,15cm}
@sp 1

@sp 1
@image{file_change_log,15cm}
@sp 1




@node Tamperproof data, , File change reports in Nova and Constellation, Security scanning
@section Tamperproof data

Message digests are supposed to be unbreakable, tamperproof
technologies, but of course everything can be broken by a sufficiently
determined attacker. Suppose someone wanted to edit a file and alter
the cfengine checksum database to cover their tracks. If they had
broken into your system, this is potentially easy to do. How can we
detect whether this has happened or not?

A simple solution to this problem is to use another checksum-based
operation to copy the database to a completely different host. By
using a copy operation based on a checksum value, we can also remotely
detect a change in the checksum database itself.

Consider the following code: 

@cartouche
@verbatim
bundle agent neighbourhood_watch
{
vars:

  "neighbours" slist => peers("/var/cfengine/inputs/hostlist","#.*",4),
             comment => "Get my neighbours from a list of all hosts";

files:

  # Redundant cross monitoring .......................................

  "$(sys.workdir)/nw/$(neighbours)_checksum_digests.db"

     comment => "Watch our peers remote hash tables and keep a local copy",
    copyfrom => remote_cp("$(sys.workdir)/checksum_digests.db",$(neighbours)),
  depends_on => { "grant_hash_tables" };

  # Define the actual children to watch over .........................

   "/usr/bin"         
      comment     => "Watch over the system binaries - changes are mostly updates",
      changes      => detect_all_change,
      depth_search => recurse("inf"),
      action       => measure;

}
@end verbatim
@end cartouche

It works by building a list of neighbours for each host. The function
SelectPartitionNeighbours can be used for this. Using a file which
contains a list of all hosts running cfengine (e.g. the cfrun.hosts
file), we create a list of hosts to copy databases from. Each host in
the network therefore takes on the responsibility to watch over its
neighbours.

The copy rule attempts to copy the database to some file in a
safekeeping directory. We label the destination file with $(this)
which becomes the name of the server from which the file was
collected. Finally, we backup any successful copies using a timestamp
to retain a complete record of all changes on the remote host. Each
time a change is detected, a copy will be kept of the old. The rule
contains triggers to issue alerts and warnings too just to make sure
the message will be heard.

In theory, all four neigbours should signal this change. If an
attacker had detailed knowledge of the system, he or she might be able
to subvert one or two of these before the change was detected, but it
is unlikely that all four could be covered up. At any rate, this
approach maximizes the chances of change detection.

Finally, in order to make this copy, you must, of course, grant access to the database in cfservd.conf. 

@verbatim
     # cfservd.conf

     admit:

     any::

       /var/cfengine/checksum_digests.db  mydomain.tld
@end verbatim

Let us now consider what happens if an attacker changes a file an
edits the checksum database. Each of the four hosts that has been
designated a neighbour will attempt to update their own copy of the
database. If the database has been tampered with, they will detect a
change in the md5 checksums of the remote copy versus the
original. The file will therefore be copied.

It is not a big problem that others have a copy of your checksum
database. They cannot see the contents of your files from this. A
potentially greater problem is that this configuration will unleash an
avalanche of messages if a change is detected. This does make messages
visible however.


@node Change detection bundle summary,  , Tamperproof data, Tamperproof data
@subsection Change detection bundle summary

@cartouche
@verbatim

bundle agent change_management
{
vars:

  "watch_files" slist =>  {
                          "/etc/passwd", 
                          "/etc/shadow", 
                          "/etc/group", 
                          "/etc/services" 
                          };

  "watch_dirs" slist =>   {
                          "/usr"
                          };


  "neighbours"   slist => peers("/var/cfengine/inputs/hostlist","#.*",4),
               comment => "Partition the network into groups using a host list";

files:

   # Basic change detection

   "$(watch_dirs)"
      comment      => "Change detection on the directories",
      changes      => detect_all_change,
      depth_search => recurse("inf");

   "$(watch_files)" 
      comment      => "Change detection on important files",
      changes      => diff;  # diff_noupdate

  # Redundant cross monitoring ... neighbourhood watch

  "$(sys.workdir)/nw/$(neighbours)_checksum_digests.db"

     comment => "Watching our peers remote hash tables for changes - cross check",
   copy_from => remote_cp("$(sys.workdir)/checksum_digests.db","$(neighbours)"),
  depends_on => { "grant_hash_tables" },
      action => neighbourwatch("File hash changes observed on $(neighbours) (neighbourhood watch)");
}

#######################################################

body action neighbourwatch(s)
{
ifelapsed    => "30";
log_string   => "$(s)";
log_repaired => "stdout";
}

@end verbatim
@end cartouche



@node Process and network scanning
@chapter Process and network scanning

Looking at file changes is a very static view of system change -- basically you assume that
the system should not change from some initial snaphot, or at the very least you warn about
every change. However, many aspects of a system change all the time, e.g. the network connections
to and from the host, the processes running on the system.

CFEngine's cf-montord has the ability to learn the trends and
behaviour of any countable or measurable value on the system. Over
time, it employs machine-learning methods from artificial intelligence
to build a normalcy profile for the system. Any significant deviations from
these profiles can be reported and responded to in policy.







@node Threshold monitoring,  , Breakin, Scanning logs with cf-monitord
@section Threshold monitoring

@verbatim
vars:

 "probes" slist => { "www", "smtp", "ssh" };

classes:

 "$(probes)_threshold" expression => isgreaterthan("$(mon.$(probes))","50");

reports:

  "Help $(probes)!" ifvarclass => "$(probes)_threshold";

@end verbatim



@node Log scanning
@chapter Log scanning

In CFEngine Nova and above, you can extract data from the
system in sophisticated ways from files or pipes, using Perl
Compatible Regular Expressions to match text. The @code{cf-monitord}
agent is responsible for processing measurement promises.

In this example, we count lines matching a pattern in a file.
You might want to scan a log for instances of a particular
message and trace this number over time.


@node  Scanning log files for patterns, FTP, Scanning logs with cf-monitord, Scanning logs with cf-monitord
@section Scanning log files for patterns
@sp 1

You will have to scan the log file for each separate summary
you want to keep, so you win a lot of efficiency by lumping
together mulitple patterns in a longer regular expressions.

Be careful however about the trade-off. Disk access is certainly the
most expensive computing resource, but a smart filesystem might do good caching.

Regular expression processing, on the other hand, is CPU expensive, so
if you have very long or complex patterns to match, you will begin
to eat up CPU time too. 

At the end of the day, you should probably do some tests to find a good
balance.  One goal of CFEngine is to minimally impact your system performance,
but it is possible to write promises that have the opposite effect.  Check
your work!

@verbatim

bundle monitor watch
{
measurements:

   "/home/mark/tmp/file"

         handle => "line_counter",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log("MYLINE.*"),
   history_type => "log",
         action => sample_rate("0");

}

##########################################################

body match_value scan_log(line)
{
select_line_matching => "$(line)";
track_growing_file => "true";
}

body action sample_rate(x)
{
ifelapsed => "$(x)";
expireafter => "10";
}
@end verbatim

@node  FTP, DNS, Scanning log files for patterns, Scanning logs with cf-monitord
@section Scanning syslog for FTP statistics
@sp 1

There are many things that you can set CFEngine at monitoring.  For example,
CFEngine can automtically collect information about the number of socket-level
connections made to the ftp server, but you might want more detailed
statistics.  For example, you might want to track the volume of data sent
and received, or the number of failed logins.  Here are a collection of
monitoring promises for doing just that.

Note that the ftp logs are maintained by syslog, so it is necessary to match
only those lines which correspond to the appropriate service.  We also assume
that the specific messages are sent to @file{/var/log/messages}, while your
configuration may specify otherwise.  Likewise, your operating systems's
version of ftp may issue messages with a slightly different format than ours

@verbatim

bundle monitor watch_ftp
{
vars:
   "dir" slist => { "get", "put" };

measurements:

   "/var/log/messages"

	handle => "ftp_bytes_${dir}",
   stream_type => "file",
     data_type => "int",
   match_value => extract_log(".*ftpd\[.*", ".*${dir} .* = (\d+) bytes.*"),
  history_type => "log",
	action => sample_rate("0");

   "/var/log/messages"

	handle => "ftp_failed_login",
   stream_type => "file",
     data_type => "counter",
   match_value => scan_log(".*ftpd\[.*", ".*FTP LOGIN FAILED.*"),
  history_type => "log",
	action => sample_rate("0");

   "/var/log/messages"

	handle => "ftp_failed_anonymous_login",
   stream_type => "file",
     data_type => "counter",
   match_value => scan_log(".*ftpd\[.*", ".*ANONYMOUS FTP LOGIN REFUSED.*"),
  history_type => "log",
	action => sample_rate("0");

}

##########################################################

body match_value scan_log(line)
{
select_line_matching => "$(line)";
track_growing_file => "true";
}

body match_value extract_log(line, extract)
{
select_line_matching => "$(line)";
extraction_regex => "$(extract)";
track_growing_file => "true";
}

body action sample_rate(x)
{
ifelapsed => "$(x)";
expireafter => "10";
}
@end verbatim

@node  DNS, Email, FTP, Scanning logs with cf-monitord
@section Scanning DNS logs for query statistics
@sp 1

Another thing you might want to do is monitor the types of queries that your
DNS server is being given.  One possible reason for this is to test for
unusual behavior.  For example, suddenly seeing a surge in @samp{MX} requests
might indicate that your system is being targeted by spammers (or that one of
your users is sending spam).  If you are thinking of converting to IPv6, you
might want to compare the number of @samp{A} requests to @samp{AAAA} and
@samp{A6} requests to see how effective your IPv6 implementation is.

Because DNS logs are directly maintained by @samp{bind} or @samp{named} (and
do not go through syslog), the parsing can be simpler.  However, you @i{do}
need to configure DNS to log query requests to the appropriate log file.  In
our case, we use @file{/var/log/named/queries}.

@verbatim

bundle monitor watch_dns
{
vars:
    "query_type" slist => { "A", "AAAA", "A6", "CNAME", "MX", "NS",
                            "PTR", "SOA", "TXT", "SRV", "ANY" };
measurements:
    "/var/log/named/queries"
        handle => "DNS_$(query_type)_counter",
        stream_type => "file",
        data_type => "counter",
        match_value => scan_log(".* IN $(query_type).*"),
        history_type => "log",
        action => sample_rate("0");
}

##########################################################

body match_value scan_log(line)
{
select_line_matching => "$(line)";
track_growing_file => "true";
}

body action sample_rate(x)
{
ifelapsed => "$(x)";
expireafter => "10";
}
@end verbatim

@node  Email, Milter, DNS, Scanning logs with cf-monitord
@section Scanning syslog for email statistics
@sp 1

Email is another syslog-based facility that you may want to use CFEngine to
monitor.  There are a number of volumetric data that are of interest.  For
example, the number of messages sent and received, the number of messages
that have been deferred (a large number might indicate networking problems or
spam bounces), and the number of spam messages that have been
detected and removed by the assorted spam filters.

The samples below assume that there is a separate logfile for email (called
@file{/var/log/maillog}) and that a few of the standard sendmail rulesets
have been enabled (see
@samp{http://www.sendmail.org/~ca/email/relayingdenied.html} for details).
As with any syslog-generated file, you need to check for the appropriate
service, and in this case we are lumping local messages (sent through
@samp{sm-mta}) and remote messages (sent through @samp{sendmail}) into a
single count.  Your mileage may of course vary.

If you use one or more sendmail "milters", each of these will also output
their own syslog messages, and you may choose to track the volume of
rejections on a per-filter basis.

@verbatim

bundle monitor watch_email
{
vars:
    "sendmail" string => ".*(sendmail|sm-mta)\[.*";

    "action" slist => { "Sent", "Deferred" };

measurements:

   "/var/log/maillog"

         handle => "spam_rejected",
    stream_type => "file",
      data_type => "counter",
                   # This matches 3 kinds of rulesets: check_mail,
		   # check_rcpt, and check_relay
    match_value => scan_log("$(sendmail)ruleset=check_(mail|rcpt|relay).*"),
   history_type => "log",
         action => sample_rate("0");

   "/var/log/maillog"

         handle => canonify("mail_$(action)",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log("$(sendmail)stat=$(action) .*"),
   history_type => "log",
         action => sample_rate("0");

}

##########################################################

body match_value scan_log(line)
{
select_line_matching => "$(line)";
track_growing_file => "true";
}

body action sample_rate(x)
{
ifelapsed => "$(x)";
expireafter => "10";
}
@end verbatim


@node  Milter, Breakin, Email, Scanning logs with cf-monitord
@section Scanning syslog for email milter failures
@sp 1

Milters are relatively new in sendmail, and some have problems.  You can also
use monitoring to detect certain types of failure modes.  For example, if a
milter is running (that is, there is a process present) but it does not
respond correctly, sendmail will log an entry like this in syslog (where
@samp{xyzzy} is the name of the milter in question):

@verbatim
Milter (xyzzy): to error state
@end verbatim

A small number of these messages is no big deal, since sometimes the milter
has temporary problems or simply encounters an email message that it finds
confounding.  But a larger value of these messages usually indicates that the
milter is in a broken state, and should be restarted.

You can use @samp{cf-monitord} to check for the number of these kinds of
messages, and use the soft classes that it creates to change how
@samp{cf-agent} operates.  For example, here we will restart any milter
which is showing a high number of failure-mode messages:

@verbatim
bundle monitor watch_milter
{
vars:
   "milter" slist => { "dcc", "bogom", "greylist" };

measurements:

   "/var/log/maillog"

         handle => "${milter}_errors",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*Milter (${milter}): to error state"),
   history_type => "log",
         action => sample_rate("0");
}

bundle agent fix_milter
{
vars:
    "m[dcc]" string      => "/var/dcc/libexec/start-dccm";
    "m[bogom]" string    => "/usr/local/etc/rc.d/milter-bogom.sh restart";
    "m[greylist]" string => "/usr/local/etc/rc.d/milter-greylist restart";

commands:
    "$(m[$(watch_milter.milter)])"
	ifvarclass => "$(watch_milter.milter)_high";
}
@end verbatim


@node  Breakin, Threshold monitoring, Milter, Scanning logs with cf-monitord
@section Scanning syslog for breakin attempts
@sp 1

A lot of script-kiddies will probe your site for vulnerabilities, using
dictionaries of account/password combinations, looking for unguarded accounts
or accouts with default passwords.  Most of these scans are harmless, because
a well-maintained site will not use the default passwords that these hackers
seek to exploit.

However, knowing that you are being scanned is a good thing, and CFEngine can
help you find that out.  Because @samp{sshd} logs it's message through
@samp{syslog}, we again need to filter lines based on the service name.  On
our system, authorization messages are routed to @file{/var/log/auth.log},
and we would monitor it like this:

@verbatim
bundle monitor watch_breakin_attempts
{
measurements:
    "/var/log/auth.log"
	 # This is likely what you'll see when a script kiddie probes
	 # your system

         handle => "ssh_username_probe",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*Invalid user.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # As scary as this looks, it may just be because someone's DNS
	 # records are misconfigured - but you should double check!

         handle => "ssh_reverse_map_problem",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*POSSIBLE BREAK-IN ATTEMPT!.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # Someone is trying to log in to an account that is locked
	 # out in the sshd config file

         handle => "ssh_denygroups",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*group is listed in DenyGroups.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # This is more a configuration error in /etc/passwd than a
	 # breakin attempt...

         handle => "ssh_no_shell",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*because shell \S+ does not exist.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # These errors usually indicate a problem authenticating to your
	 # IMAP or POP3 server

         handle => "ssh_pam_error",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*error: PAM: authentication error.*"),
   history_type => "log",
         action => sample_rate("0");

    "/var/log/auth.log"
	 # These errors usually indicate that you haven't rebuilt your
	 # database after changing /etc/login.conf - maybe you should
	 # include a rule to do this command: cap_mkdb /etc/login.conf

         handle => "ssh_pam_error",
    stream_type => "file",
      data_type => "counter",
    match_value => scan_log(".*sshd\[.*login_getclass: unknown class.*"),
   history_type => "log",
         action => sample_rate("0");
}

@end verbatim


See the CFEngine Nova documentation for more possibilities of measurement
promises.



@node Intrusion detection,  , TCP dump, Security scanning
@chapter Intrusion detection

Intrusion detection is a highly specialized area.  CFEngine is not
designed specifically to be an intrusion detection or intrusion
prevention system, but it has many features that can be used as part
of an integrated stratey against intrusions.

What is an intrusion or an attempted intrusion? This can be difficult
to define. If someone tries to login as root once? If someone tries to
login at root fifty times? Is port scanning a sign, or perhaps a SATAN
or ISS scan? Someone trying a known security hole? There is no certain
way to identify the intentions behind activity we observe on a system.

The aim of an intrusion detection system is to detect events that can
be plausibly connected to incidents or break-ins, hopefully while they
are still in progress so that something can be done about them.
One way of doing fault diagnosis is to compare a system to a working
specification continuously. This is essentially what CFEngine does
with systems.


@bye
